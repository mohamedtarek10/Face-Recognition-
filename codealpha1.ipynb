{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout ,BatchNormalization, GlobalAveragePooling2D,MaxPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from Evaluation_matrices import f1\n",
    "import keras\n",
    "from keras import layers , metrics \n",
    "from tensorflow.keras import layers, models\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import  ModelCheckpoint ,ReduceLROnPlateau ,EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from Evaluation_matrices import f1\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'path to dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ed463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each subfolder (class) in the data directory\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    # Ensure it's a directory\n",
    "    if os.path.isdir(class_dir):\n",
    "        # Loop through each image file in the subfolder\n",
    "        for img_file in os.listdir(class_dir):\n",
    "            # Read the image\n",
    "            img_path = os.path.join(class_dir, img_file)\n",
    "            # Check if image file exists\n",
    "            if os.path.isfile(img_path):\n",
    "                img = cv2.imread(img_path)\n",
    "                # Check if image is loaded successfully\n",
    "                if img is not None:\n",
    "                    # Resize the image if necessary\n",
    "                    img = cv2.resize(img, (224, 224))  # Adjust size as needed\n",
    "                    # Append the image and corresponding label\n",
    "                    images.append(img)\n",
    "                    labels.append(class_name)\n",
    "                else:\n",
    "                    print(f\"Error: Unable to load image '{img_path}'\")\n",
    "            else:\n",
    "                print(f\"Error: File '{img_path}' does not exist\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "num_classes =y_train.shape[0]\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c19da",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "print(len(y_train_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71425fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "model.add(Dense(len(np.unique(labels)), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae8942c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = callbacks.ModelCheckpoint(r'path to save model weights', verbose=1, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "checkpoint1 = callbacks.ModelCheckpoint(r'path to save .h5',save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-10, verbose=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "callbacks = [checkpoint1, checkpoint, reduce_lr,early_stop]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt_adam = tf.keras.optimizers.experimental.Adam(1e-3)\n",
    "# Define RMSprop optimizer\n",
    "#opt_rmsprop = RMSprop(learning_rate=1e-3)\n",
    "\n",
    "# Define SGD optimizer with momentum\n",
    "#opt_sgd = SGD(learning_rate=1e-3, momentum=0.9)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              \n",
    "              optimizer=opt_adam,\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d05f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, validation_data=validation_generator ,\n",
    "          steps_per_epoch=40,\n",
    "          epochs=120,\n",
    "          shuffle=True, callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a784c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b94923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load your trained model\n",
    "model = load_model(r'path to saved model')\n",
    "\n",
    "# Initialize the video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the captured frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract the face region\n",
    "        face_region = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Preprocess the face region (resize, reshape, etc.) to match your model's input\n",
    "        face_region_preprocessed = downsample_image(face_region)\n",
    "        face_region_preprocessed = np.stack((face_region_preprocessed,)*3, axis=-1)  # Convert to 3 channels\n",
    "        face_region_preprocessed = face_region_preprocessed.reshape(1, 224, 224, 3) / 255.0  # Add batch dimension and normalize\n",
    "\n",
    "        # Predict the identity using your model\n",
    "        predictions = model.predict(face_region_preprocessed)\n",
    "        predicted_id  = np.argmax(predictions)\n",
    "        predicted_identity = reverse_class_id_map[predicted_id] if predicted_id in reverse_class_id_map else \"Unknown\"\n",
    "\n",
    "        # Display the predicted identity and ID on the frame\n",
    "        display_text = f\"ID: {predicted_id}, Name: {predicted_identity}\"\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, display_text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Break the loop with the 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051448d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0c7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
