{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import h5py\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Model_face_recogination import model\n",
    "from keras import callbacks\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import csv\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'Path to your dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ed463",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\");\n",
    "\n",
    "\n",
    "def downsample_image(img):\n",
    "    img = Image.fromarray(img.astype('uint8'), 'L')\n",
    "    img = img.resize((224, 224), Image.LANCZOS)\n",
    "    return np.array(img)\n",
    "\n",
    "\n",
    "# function to get the images and label data\n",
    "def getImagesAndLabels(path):\n",
    "    path = r'Path to your dataset'\n",
    "    imagePaths = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "\n",
    "    class_id_map = {}\n",
    "    next_id = 1\n",
    "    faceSamples = []\n",
    "    ids = []\n",
    "\n",
    "    for imagePath in imagePaths:\n",
    "        # If there is an error saving any jpegs\n",
    "        try:\n",
    "            PIL_img = Image.open(imagePath).convert('L')  # convert it to grayscale\n",
    "        except:\n",
    "            continue\n",
    "        img_numpy = np.array(PIL_img, 'uint8')\n",
    "\n",
    "        # Extract class name from image path\n",
    "        file_name = os.path.split(imagePath)[-1]\n",
    "        class_name = file_name.split(\".\")[1]  # Extract the class name after the dot\n",
    "\n",
    "        # Assign a unique ID to the class if it's not already assigned\n",
    "        if class_name not in class_id_map:\n",
    "            class_id_map[class_name] = next_id\n",
    "            next_id += 1  # Increment the ID counter\n",
    "\n",
    "        id = class_id_map[class_name]\n",
    "        faceSamples.append(img_numpy)\n",
    "        ids.append(id)\n",
    "\n",
    "    return faceSamples, ids, class_id_map\n",
    "\n",
    "faces, ids, class_id_map = getImagesAndLabels(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "n_faces = len(set(ids))\n",
    "model = model((224, 224, 3), n_faces)\n",
    "# faces = np.asarray(faces)\n",
    "faces = np.array([downsample_image(ab) for ab in faces])\n",
    "ids = np.asarray(ids)\n",
    "faces = faces[:, :, :, np.newaxis]\n",
    "print(\"Shape of Data: \" + str(faces.shape))\n",
    "print(\"Number of unique faces : \" + str(n_faces))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = to_categorical(ids)\n",
    "\n",
    "\n",
    "print(len(ids))\n",
    "\n",
    "faces = faces.astype('float32')\n",
    "faces /= 255.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    faces, ids, test_size=0.1, random_state=0)\n",
    "x_train_rgb = np.repeat(x_train, 3, axis=-1)  # This will change the shape to (num_samples, 224, 224, 3) RGB images\n",
    "x_test_rgb = np.repeat(x_test, 3, axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae8942c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = callbacks.ModelCheckpoint(r'Path to save model ', verbose=1, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "checkpoint1 = callbacks.ModelCheckpoint(r'Path to save model.h5 file',save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "callbacks = [checkpoint1, checkpoint, reduce_lr,early_stop]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d05f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(x_train_rgb, y_train, batch_size=32),\n",
    "          steps_per_epoch=40,\n",
    "          epochs=120,\n",
    "          validation_data=(x_test_rgb, y_test),\n",
    "          shuffle=True, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert integer IDs to string IDs\n",
    "reverse_class_id_map = {v: k for k, v in class_id_map.items()}\n",
    "ids_list = ids.argmax(axis=1)\n",
    "ids_str = [reverse_class_id_map[i] for i in ids_list]\n",
    "\n",
    "print(\"Classes:\", class_id_map)\n",
    "\n",
    "\n",
    "\n",
    "# Print the number of faces trained and end program\n",
    "print(\"\\n [INFO] \" + str(n_faces) + \" faces trained. Exiting Program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a784c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b87fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(r'Path to load your model')\n",
    "loss, accuracy = model.evaluate(\n",
    "    x=x_test_rgb,\n",
    "    y=y_test,\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777b6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the test loss and accuracy\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ce6f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(r'Path to load your model')\n",
    "\n",
    "# Load the face detection classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Directory containing images\n",
    "image_folder = r'Path to test images'\n",
    "\n",
    "# Initialize CSV File for logging attendance\n",
    "csv_file = r'path to your csv file to take attendance'\n",
    "fieldnames = ['ID', 'Name', 'Date', 'Time', 'File']\n",
    "with open(csv_file, 'a', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    if file.tell() == 0:  # Write header only if file is empty\n",
    "        writer.writeheader()\n",
    "\n",
    "def log_attendance(person_id, person_name, image_file):\n",
    "    with open(csv_file, 'a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writerow({\n",
    "            'ID': person_id,\n",
    "            'Name': person_name,\n",
    "            'Date': datetime.date.today().isoformat(),\n",
    "            'Time': datetime.datetime.now().strftime(\"%H:%M:%S\"),\n",
    "            'File': os.path.basename(image_file)\n",
    "        })\n",
    "\n",
    "# List all image files in the directory\n",
    "image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Iterate over each image file\n",
    "for image_file in image_files:\n",
    "    # Read the image\n",
    "    frame = cv2.imread(image_file)\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # For each detected face, classify and print the prediction\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract the face region from the frame\n",
    "        face_region = gray[y:y+h, x:x+w]\n",
    "\n",
    "        face_region_preprocessed = downsample_image(face_region)\n",
    "        face_region_preprocessed = np.stack((face_region_preprocessed,)*3, axis=-1)  # Convert to 3 channels\n",
    "        face_region_preprocessed = face_region_preprocessed.reshape(1, 224, 224, 3) / 255.0  # Add batch dimension and normalize\n",
    "\n",
    "        # Predict the identity using your model\n",
    "        predictions = model.predict(face_region_preprocessed)\n",
    "        predicted_id = np.argmax(predictions)\n",
    "        predicted_identity = reverse_class_id_map[predicted_id] if predicted_id in reverse_class_id_map else \"Unknown\"\n",
    "\n",
    "        # Log the attendance in the CSV file\n",
    "        log_attendance(predicted_id, predicted_identity, image_file)\n",
    "\n",
    "        # Display the predicted identity and ID on the frame\n",
    "        display_text = f\"ID: {predicted_id}, Name: {predicted_identity}\"\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, display_text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "        print(display_text)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Break the loop with the 'q' key\n",
    "    if cv2.waitKey(200) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b94923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load your trained model\n",
    "model = load_model(r'Path to load your model')\n",
    "\n",
    "# Initialize the video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# CSV file setup\n",
    "csv_file = r'path to your csv file to take attendance'\n",
    "fieldnames = ['ID', 'Name', 'Date', 'Time']\n",
    "with open(csv_file, 'a', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    if file.tell() == 0:  # Write header only if file is empty\n",
    "        writer.writeheader()\n",
    "\n",
    "def log_attendance(person_id, person_name):\n",
    "    with open(csv_file, 'a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writerow({\n",
    "            'ID': person_id,\n",
    "            'Name': person_name,\n",
    "            'Date': datetime.date.today().isoformat(),\n",
    "            'Time': datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "        })\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the captured frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract the face region\n",
    "        face_region = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Preprocess the face region (resize, reshape, etc.) to match your model's input\n",
    "        face_region_preprocessed = downsample_image(face_region)\n",
    "        face_region_preprocessed = np.stack((face_region_preprocessed,)*3, axis=-1)  # Convert to 3 channels\n",
    "        face_region_preprocessed = face_region_preprocessed.reshape(1, 224, 224, 3) / 255.0  # Add batch dimension and normalize\n",
    "\n",
    "        # Predict the identity using your model\n",
    "        predictions = model.predict(face_region_preprocessed)\n",
    "        predicted_id  = np.argmax(predictions)\n",
    "        predicted_identity = reverse_class_id_map[predicted_id] if predicted_id in reverse_class_id_map else \"Unknown\"\n",
    "\n",
    "        # Log the attendance in the CSV file\n",
    "        log_attendance(predicted_id, predicted_identity)\n",
    "\n",
    "        # Display the predicted identity and ID on the frame\n",
    "        display_text = f\"ID: {predicted_id}, Name: {predicted_identity}\"\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, display_text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Break the loop with the 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051448d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0c7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
